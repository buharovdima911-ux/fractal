@article{SohlDickstein2024,
  author    = {Jascha Sohl-Dickstein},
  title     = {The boundary of neural network trainability is fractal},
  journal   = {arXiv preprint arXiv:2402.06184},
  year      = {2024},
  url       = {https://arxiv.org/abs/2402.06184},
  note      = {Доступно: \url{https://arxiv.org/abs/2402.06184}}
}

@misc{SohlDicksteinBlog2024,
  author    = {Jascha Sohl-Dickstein},
  title     = {Neural network training makes beautiful fractals},
  year      = {2024},
  howpublished = {Blog post},
  url       = {https://sohl-dickstein.github.io/2024/02/12/fractal.html},
  note      = {Доступно: \url{https://sohl-dickstein.github.io/2024/02/12/fractal.html}}
}

@inproceedings{Kong2020,
  author    = {Lingjiong Kong and Molei Tao},
  title     = {Stochasticity of Deterministic Gradient Descent: Large Learning Rate for Multiscale Objective Function},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2020},
  pages     = {1--12},
  url       = {https://proceedings.neurips.cc/paper/2020/file/1b9a80606d74d3da6db2f1274557e644-Paper.pdf},
  note      = {Доступно: \url{https://proceedings.neurips.cc/paper/2020/file/1b9a80606d74d3da6db2f1274557e644-Paper.pdf}}
}

@article{Chen2023,
  author    = {Xiang Chen and Kaizheng Wang and Pragya Sur},
  title     = {From Stability to Chaos: Analyzing Gradient Descent Dynamics in Quadratic Regression},
  journal   = {arXiv preprint arXiv:2310.01687},
  year      = {2023},
  url       = {https://arxiv.org/abs/2310.01687},
  note      = {Доступно: \url{https://arxiv.org/abs/2310.01687}}
}

@inproceedings{Cohen2021,
  author    = {Jeremy M. Cohen and Simran Kaur and Yuanzhi Li and J. Zico Kolter and Ameet Talwalkar},
  title     = {Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.00065},
  note      = {Доступно: \url{https://arxiv.org/abs/2103.00065}}
}

@article{Liu2024,
  author    = {Yuxin Liu and Ludovic Arnould and Jascha Sohl-Dickstein},
  title     = {Complex Fractal Trainability Boundary Can Arise from Trivial Non-convexity},
  journal   = {arXiv preprint arXiv:2406.13971},
  year      = {2024},
  url       = {https://arxiv.org/abs/2406.13971},
  note      = {Доступно: \url{https://arxiv.org/abs/2406.13971}}
}

@article{Torkamandi2025,
  author    = {Mohammadamin Tavakoli and Torkamandi and others},
  title     = {Mapping the Edge of Chaos: Fractal-Like Boundaries in The Trainability of Decoder-Only Transformer Models},
  journal   = {arXiv preprint arXiv:2501.04286},
  year      = {2025},
  url       = {https://arxiv.org/abs/2501.04286},
  note      = {Доступно: \url{https://arxiv.org/abs/2501.04286}}
}

@book{Mandelbrot1982,
  author    = {Benoit B. Mandelbrot},
  title     = {The Fractal Geometry of Nature},
  publisher = {W. H. Freeman and Company},
  year      = {1982},
  address   = {New York}
}

@article{Feigenbaum1978,
  author    = {Mitchell J. Feigenbaum},
  title     = {Quantitative universality for a class of nonlinear transformations},
  journal   = {Journal of Statistical Physics},
  volume    = {19},
  number    = {1},
  pages     = {25--52},
  year      = {1978},
  doi       = {10.1007/BF01020332}
}

@book{Strogatz2015,
  author    = {Steven H. Strogatz},
  title     = {Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering},
  publisher = {Westview Press},
  edition   = {2nd},
  year      = {2015},
  address   = {Boulder, CO}
}

@article{Falconer2014,
  author    = {Kenneth Falconer},
  title     = {Fractal Geometry: Mathematical Foundations and Applications},
  publisher = {John Wiley \& Sons},
  edition   = {3rd},
  year      = {2014}
}

@misc{PoreSpy,
  author    = {Jeff T. Gostick and others},
  title     = {PoreSpy: A Python toolkit for quantitative analysis of porous media images},
  year      = {2019},
  howpublished = {Software package},
  url       = {https://porespy.org/},
  note      = {Документация: \url{https://porespy.org/examples/metrics/tutorials/computing_fractal_dim.html}}
}

@article{Bottou2018,
  author    = {L{\'e}on Bottou and Frank E. Curtis and Jorge Nocedal},
  title     = {Optimization Methods for Large-Scale Machine Learning},
  journal   = {SIAM Review},
  volume    = {60},
  number    = {2},
  pages     = {223--311},
  year      = {2018},
  doi       = {10.1137/16M1080173}
}

@inproceedings{Goodfellow2016,
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  title     = {Deep Learning},
  publisher = {MIT Press},
  year      = {2016},
  address   = {Cambridge, MA},
  url       = {http://www.deeplearningbook.org}
}

@article{Smith2018,
  author    = {Samuel L. Smith and Pieter-Jan Kindermans and Chris Ying and Quoc V. Le},
  title     = {Don't Decay the Learning Rate, Increase the Batch Size},
  journal   = {arXiv preprint arXiv:1711.00489},
  year      = {2018},
  url       = {https://arxiv.org/abs/1711.00489}
}

@inproceedings{Nesterov1983,
  author    = {Yurii Nesterov},
  title     = {A method for solving the convex programming problem with convergence rate O(1/k²)},
  booktitle = {Soviet Mathematics Doklady},
  volume    = {27},
  pages     = {372--376},
  year      = {1983}
}

@book{Nocedal2006,
  author    = {Jorge Nocedal and Stephen J. Wright},
  title     = {Numerical Optimization},
  publisher = {Springer},
  edition   = {2nd},
  year      = {2006},
  address   = {New York}
}

@misc{PyTorch,
  author    = {Adam Paszke and others},
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  year      = {2019},
  howpublished = {Software framework},
  url       = {https://pytorch.org/},
  note      = {Version 2.0+}
}
